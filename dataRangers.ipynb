{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Rangers: Ingenieria de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La base de datos se desplego localmente, en la ultima imagen de docker de ```postgresql```. Como se detalla en el ```README.md```. Si se cuenta con una base de datos inicial se pueden reemplazar los valores en el archivo ```.env```\n",
    "\n",
    "- En este caso se asume que las tablas pueden o no estar creada dentro de la empresa, de ahi que se usan los objetos relacionales de sqlalchemy para mapear estas tablas con sus columnas y esquemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este pipeline en particular simulando procesamiento cercano al tiempo real, es importante que los archivos no se almacenen en memoria. Para ello, se utilizan generadores, que al final terminan siendo objetos (mucho mas reducidos comparado al peso del archivo).  \n",
    "Estos objetos van a arrojar un iterable que luego vamos a poder acceder siempre que se necesite. Es similar al lazy-evaluation de ``` apache spark```.  \n",
    "\n",
    "En ese sentido, se utilizo la palabra clave ```yield``` y se accedio al archivo solo cuando se necesita.  Adicional, se aprovecho la funcionalidad de la API de Pandas para generar chunks, estos chunks tambien funcionan creando un objeto iterable que luego podemos acceder cuando se necesita y asi realizar la ingesta.  \n",
    "\n",
    "#### Este pipeline tiene las siguientes ventajas:\n",
    "- Carga informacion solo cuando se necesita.\n",
    "- Procesa cada fila de forma individual.\n",
    "- Parcialmente utiliza el ORM de sqlalchemy lo que lo hace bastante sencillo luego de integrar con API`s basadas en ```Flask```,```Django``` o ```Fast API``` o en su defecto, utilizando el ORM propio de estos frameworks. \n",
    "\n",
    "#### A su vez, tiene estos puntos por mejorar:\n",
    "- Configurar de tal manera que el motor de base de datos pueda ser determinado por el usuario que programa el pipeline.\n",
    "- Insertar pruebas unitarias\n",
    "- Utilizar frameworks mas avanzados en procesamiento NRT (near-real-time) como ```apache akafka```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dbconfig as dbc # Modulo de configuraciones en carpeta utils\n",
    "\n",
    "from utils.functions   import list_datafile # Funcion para listar archivos\n",
    "\n",
    "from utils.logs        import PipelineLogs  # Clase para los logs\n",
    "from database.database import Database      # Clase para conexion a base de datos\n",
    "\n",
    "from etl_pipeline      import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables de entorno:\n",
    "USER = dbc.DB_USER\n",
    "PWD  = dbc.DB_PASSWORD\n",
    "HOST = dbc.DB_HOST\n",
    "DB   = dbc.DATABASE_NAME\n",
    "\n",
    "CHUNKSIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist = list_datafile(path='./data')\n",
    "\n",
    "plsqldb = Database(HOST, USER, PWD, DB)\n",
    "\n",
    "logs = PipelineLogs(\"pipeline-prove\", \"pipeline.log\").pipeline_logs()\n",
    "\n",
    "pipeline(pathlist, plsqldb, CHUNKSIZE, logs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
